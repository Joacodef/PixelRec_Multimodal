"""
Novelty and diversity metrics for recommendation evaluation.

This module provides classes and functions to calculate various metrics related to
the novelty and diversity of recommendations generated by a recommender system.
These metrics go beyond traditional accuracy measures to assess how well a system
recommends unique, surprising, or varied items to users.
"""
import numpy as np
from typing import List, Dict, Set, Tuple, Optional
from collections import Counter
import pandas as pd


class NoveltyMetrics:
    """
    Calculates novelty and diversity metrics for a set of recommendations.

    This class processes information about item popularity and user interaction history
    to compute various metrics such as self-information, inverse item frequency,
    catalog coverage, popularity statistics, long-tail percentage, intra-list diversity,
    and personalized novelty.
    """
    
    def __init__(
        self, 
        item_popularity: Dict[str, float],
        user_history: List[Tuple[str, str]]
    ):
        """
        Initializes the NoveltyMetrics calculator.
        
        Args:
            item_popularity: A dictionary mapping item IDs (string) to their popularity scores (float).
                             Popularity scores typically represent the total number of interactions
                             an item has received.
            user_history: A list of (user_id, item_id) tuples representing all user-item interactions.
                          This data is used to derive global user and item interaction counts
                          and for personalized novelty calculations.
        """
        self.item_popularity = item_popularity
        self.user_history = user_history
        
        # Calculates derived statistics from the input data.
        self.total_interactions = sum(item_popularity.values())
        self.n_users = len(set(user for user, _ in user_history))
        self.item_user_counts = self._calculate_item_user_counts()
        self.popularity_ranks = self._calculate_popularity_ranks()
        
    def _calculate_item_user_counts(self) -> Counter:
        """
        Calculates the number of unique users that have interacted with each item.

        Returns:
            A Counter object where keys are item IDs (string) and values are
            the number of unique users who interacted with that item.
        """
        # Iterates through the user history to count occurrences of each item.
        return Counter(item for _, item in self.user_history)
    
    def _calculate_popularity_ranks(self) -> Dict[str, int]:
        """
        Calculates the popularity rank for each item based on `item_popularity`.

        Items are ranked from most popular (rank 0) to least popular.

        Returns:
            A dictionary mapping item IDs (string) to their popularity rank (integer).
        """
        # Sorts items by popularity score in descending order.
        sorted_items = sorted(
            self.item_popularity.items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        # Assigns a rank to each item based on its position in the sorted list.
        return {item: rank for rank, (item, _) in enumerate(sorted_items)}
    
    def calculate_metrics(
        self, 
        recommendations: List[str], 
        user_id: Optional[str] = None
    ) -> Dict[str, float]:
        """
        Calculates a comprehensive set of novelty and diversity metrics for a list of recommendations.
        
        Args:
            recommendations: A list of recommended item IDs (string) for a single user.
                             The order of items in this list can influence some metrics (e.g., diversity).
            user_id: An optional user ID (string). If provided, personalized novelty metrics
                     that consider the user's past interactions will be calculated.

        Returns:
            A dictionary containing various novelty and diversity metrics as float values.
            Returns an empty dictionary if the input `recommendations` list is empty.
        """
        metrics = {}
        
        # Returns an empty dictionary if no recommendations are provided.
        if not recommendations:
            return metrics
        
        # Calculates average self-information, which measures the "surprisal" of items.
        metrics['avg_self_information'] = self.calculate_self_information(
            recommendations
        )
        
        # Calculates average Inverse Item Frequency (IIF), indicating how uncommon items are.
        metrics['avg_iif'] = self.calculate_iif(recommendations)
        
        # Calculates catalog coverage, representing the proportion of the entire catalog
        # covered by the recommendations.
        metrics['catalog_coverage'] = self.calculate_coverage(recommendations)
        
        # Calculates various statistics related to the popularity ranks of recommended items.
        pop_stats = self.calculate_popularity_stats(recommendations)
        metrics.update(pop_stats)
        
        # Calculates the percentage of recommended items that fall into the "long tail"
        # of the item popularity distribution.
        metrics['long_tail_percentage'] = self.calculate_long_tail_percentage(
            recommendations
        )
        
        # Calculates intra-list diversity, currently based on the percentage of unique items.
        if len(recommendations) > 1:
            metrics['diversity'] = self.calculate_diversity(recommendations)
        
        # Calculates personalized novelty if a user ID is provided, measuring how many
        # recommended items are new to the specific user.
        if user_id:
            metrics['personalized_novelty'] = self.calculate_personalized_novelty(
                recommendations, 
                user_id
            )
        
        return metrics
    
    def calculate_self_information(self, items: List[str]) -> float:
        """
        Calculates the average self-information (surprisal) of a list of items.

        Self-information is calculated as -log2(P(item)), where P(item) is the
        probability of the item appearing in the dataset. Higher values indicate
        items that are less frequent and thus more "surprising" or novel.

        Args:
            items: A list of item IDs (string) for which to calculate average self-information.

        Returns:
            The average self-information score across the provided items (float).
            Returns 0.0 if no valid items or total interactions are zero.
        """
        self_info_scores = []
        
        for item in items:
            if item in self.item_popularity and self.total_interactions > 0:
                # Calculates the empirical probability of the item.
                prob = self.item_popularity[item] / self.total_interactions
                # Adds a small epsilon to prevent issues with log(0) for extremely rare items.
                epsilon = 1e-10
                prob = max(prob, epsilon)
                # Calculates self-information.
                self_info = -np.log2(prob)
                self_info_scores.append(self_info)
        
        # Returns the average self-information, or 0.0 if no scores were collected.
        return np.mean(self_info_scores) if self_info_scores else 0.0
    
    def calculate_iif(self, items: List[str]) -> float:
        """
        Calculates the average Inverse Item Frequency (IIF) for a list of items.

        IIF is a measure of item commonness based on how many users have interacted
        with it. Higher IIF values indicate items interacted with by fewer users.
        It is computed as log(N_users / N_users_interacted_with_item).

        Args:
            items: A list of item IDs (string) for which to calculate average IIF.

        Returns:
            The average IIF score across the provided items (float).
            Returns 0.0 if no valid items or total users are zero.
        """
        iif_scores = []
        
        for item in items:
            if item in self.item_user_counts and self.n_users > 0:
                user_count = self.item_user_counts[item]
                if user_count > 0:
                    # Calculates IIF, adding a small epsilon to the denominator for numerical stability.
                    iif = np.log(self.n_users / (user_count + 1e-10))
                    iif_scores.append(iif)
        
        # Returns the average IIF score, or 0.0 if no scores were collected.
        return np.mean(iif_scores) if iif_scores else 0.0
    
    def calculate_coverage(self, items: List[str]) -> float:
        """
        Calculates the catalog coverage, i.e., the percentage of the total item catalog
        that is represented within a given set of recommendations.

        Args:
            items: A list of recommended item IDs (string).

        Returns:
            The catalog coverage score, a float between 0.0 and 1.0.
            Returns 0.0 if the item popularity data is empty.
        """
        if not self.item_popularity:
            return 0.0
        
        # Identifies the unique items within the recommended list.
        unique_items = set(items)
        # Calculates coverage as the ratio of unique recommended items to the total number of items in the catalog.
        return len(unique_items) / len(self.item_popularity)
    
    def calculate_popularity_stats(self, items: List[str]) -> Dict[str, float]:
        """
        Calculates various statistical measures for the popularity ranks of items
        within a given list of recommendations.

        Args:
            items: A list of recommended item IDs (string).

        Returns:
            A dictionary containing the average, standard deviation, minimum, and maximum
            popularity ranks of the recommended items. Returns default values (e.g., NaN for mean)
            if the input `items` list is empty or contains no items with popularity ranks.
        """
        # Retrieves the popularity rank for each item. Items not found are assigned the highest possible rank.
        rank_scores = [
            self.popularity_ranks.get(item, len(self.popularity_ranks)) 
            for item in items
        ]
        
        # Returns default statistics if no ranks were collected to avoid errors.
        if not rank_scores:
            return {
                'avg_popularity_rank': np.nan,
                'popularity_rank_std': np.nan,
                'min_popularity_rank': np.nan,
                'max_popularity_rank': np.nan
            }

        # Calculates and returns the average, standard deviation, minimum, and maximum of the ranks.
        return {
            'avg_popularity_rank': float(np.mean(rank_scores)),
            'popularity_rank_std': float(np.std(rank_scores)),
            'min_popularity_rank': float(np.min(rank_scores)),
            'max_popularity_rank': float(np.max(rank_scores))
        }
    
    def calculate_long_tail_percentage(self, items: List[str]) -> float:
        """
        Calculates the percentage of recommended items that belong to the "long tail"
        of the item popularity distribution.

        The long tail is defined as the bottom 80% of items by popularity rank.

        Args:
            items: A list of recommended item IDs (string).

        Returns:
            The percentage of long-tail items in the recommendations (float),
            between 0.0 and 1.0. Returns 0.0 if the popularity ranks are empty.
        """
        if not self.popularity_ranks:
            return 0.0
        
        # Determines the rank threshold for the long tail (bottom 80% of items).
        tail_threshold = int(len(self.popularity_ranks) * 0.2)
        # Identifies items that are considered part of the long tail.
        tail_items = {
            item for item, rank in self.popularity_ranks.items() 
            if rank >= tail_threshold
        }
        
        # Counts how many of the recommended items are in the long tail.
        tail_count = sum(1 for item in items if item in tail_items)
        # Calculates the percentage of long-tail items in the recommendations.
        return tail_count / len(items) if items else 0.0
    
    def calculate_diversity(self, items: List[str]) -> float:
        """
        Calculates intra-list diversity, which measures the uniqueness of items
        within a single list of recommendations.

        Currently, this metric is calculated as the percentage of unique items
        within the provided list. This can be extended to use item embeddings
        for more sophisticated similarity-based diversity measures.

        Args:
            items: A list of recommended item IDs (string).

        Returns:
            The intra-list diversity score (float), between 0.0 and 1.0.
            Returns 0.0 if the input `items` list is empty.
        """
        # Calculates diversity as the ratio of unique items to the total number of items.
        return len(set(items)) / len(items) if items else 0.0
    
    def calculate_personalized_novelty(
        self, 
        items: List[str], 
        user_id: str
    ) -> float:
        """
        Calculates personalized novelty, which measures how many of the recommended
        items are new to a specific user (i.e., not present in their historical interactions).

        Args:
            items: A list of recommended item IDs (string).
            user_id: The ID of the user (string) for whom to calculate personalized novelty.

        Returns:
            The personalized novelty score (float), between 0.0 and 1.0.
            Returns 0.0 if the input `items` list is empty or the user has no history.
        """
        # Retrieves the set of items the specified user has already interacted with.
        user_items = set(
            item for uid, item in self.user_history 
            if uid == user_id
        )
        
        # Identifies items in the recommendation list that are not in the user's history.
        novel_items = [item for item in items if item not in user_items]
        # Calculates personalized novelty as the ratio of novel items to total recommended items.
        return len(novel_items) / len(items) if items else 0.0


class DiversityCalculator:
    """
    Calculates diversity metrics for recommendations using item embeddings.

    This class supports calculating pairwise diversity between recommended items
    based on their embedding vectors, using various distance metrics. It also
    provides a measure of overall catalog coverage by recommendations across users.
    """
    
    def __init__(self, item_embeddings: Dict[str, np.ndarray]):
        """
        Initializes the DiversityCalculator.
        
        Args:
            item_embeddings: A dictionary mapping item IDs (string) to their
                             embedding vectors (NumPy array). These embeddings
                             are used to compute item similarity and diversity.
        """
        self.item_embeddings = item_embeddings
    
    def calculate_pairwise_diversity(
        self, 
        items: List[str], 
        metric: str = 'cosine'
    ) -> float:
        """
        Calculates the average pairwise diversity among a list of items based on their embeddings.

        Pairwise diversity is the average distance between all unique pairs of items
        in the provided list. Supported metrics are 'cosine' distance (1 - cosine similarity)
        and 'euclidean' distance.

        Args:
            items: A list of item IDs (string) for which to calculate pairwise diversity.
            metric: The distance metric to use. Options are 'cosine' or 'euclidean'.

        Returns:
            The average pairwise diversity score (float). Returns 0.0 if there are
            fewer than two items or if no valid embeddings are found for the items.
        """
        if len(items) < 2:
            return 0.0
        
        distances = []
        
        # Iterates through all unique pairs of items in the list.
        for i in range(len(items)):
            for j in range(i + 1, len(items)):
                # Ensures both items have available embeddings.
                if items[i] in self.item_embeddings and items[j] in self.item_embeddings:
                    emb_i = self.item_embeddings[items[i]]
                    emb_j = self.item_embeddings[items[j]]
                    
                    # Calculates distance based on the specified metric.
                    if metric == 'cosine':
                        # Computes cosine similarity, then converts to cosine distance (1 - similarity).
                        # Includes small epsilon for numerical stability in case of zero vectors.
                        norm_i = np.linalg.norm(emb_i)
                        norm_j = np.linalg.norm(emb_j)
                        
                        # Handles cases where one or both vectors are zero.
                        if norm_i < 1e-10 or norm_j < 1e-10:
                            distance = 1.0  # Assigns maximum distance if vectors are zero.
                        else:
                            similarity = np.dot(emb_i, emb_j) / (norm_i * norm_j)
                            # Clips similarity to [-1, 1] to mitigate floating point errors.
                            similarity = np.clip(similarity, -1.0, 1.0)
                            distance = 1 - similarity
                    else:  # Defaults to Euclidean distance.
                        distance = np.linalg.norm(emb_i - emb_j)
                    
                    distances.append(distance)
        
        # Returns the average distance, or 0.0 if no distances were calculated.
        return np.mean(distances) if distances else 0.0
    
    def calculate_coverage_diversity(
        self, 
        recommendations_per_user: Dict[str, List[str]]
    ) -> float:
        """
        Calculates the overall coverage diversity across recommendations for multiple users.
        This metric measures the proportion of unique items recommended across all users
        relative to the total number of recommendations made.

        Args:
            recommendations_per_user: A dictionary where keys are user IDs (string)
                                     and values are lists of recommended item IDs (string)
                                     for that user.

        Returns:
            The coverage diversity score (float). Returns 0.0 if no recommendations
            are provided across any users.
        """
        all_recommended_items = set()
        
        # Collects all unique recommended items across all users.
        for items in recommendations_per_user.values():
            all_recommended_items.update(items)
        
        # Calculates the total count of all recommendations made (including duplicates).
        total_recommendations = sum(
            len(items) for items in recommendations_per_user.values()
        )
        
        # Returns 0.0 if no recommendations were made.
        if total_recommendations == 0:
            return 0.0
        
        # Calculates coverage diversity as the ratio of unique recommended items to the total number of recommendations.
        return len(all_recommended_items) / total_recommendations